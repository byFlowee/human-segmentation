{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import pprint\n",
    "\n",
    "F = nn.functional\n",
    "DEBUG = False\n",
    "\n",
    "\n",
    "vgg16_dims = [\n",
    "                    (64, 64, 'M'),                                # Stage - 1\n",
    "                    (128, 128, 'M'),                              # Stage - 2\n",
    "                    (256, 256, 256,'M'),                          # Stage - 3\n",
    "                    (512, 512, 512, 'M'),                         # Stage - 4\n",
    "                    (512, 512, 512, 'M')                          # Stage - 5\n",
    "            ]\n",
    "\n",
    "decoder_dims = [\n",
    "                    ('U', 512, 512, 512),                         # Stage - 5\n",
    "                    ('U', 512, 512, 512),                         # Stage - 4\n",
    "                    ('U', 256, 256, 256),                         # Stage - 3\n",
    "                    ('U', 128, 128),                              # Stage - 2\n",
    "                    ('U', 64, 64)                                 # Stage - 1\n",
    "                ]\n",
    "\n",
    "\n",
    "class SegNet(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(SegNet, self).__init__()\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "\n",
    "        self.num_channels = input_channels\n",
    "\n",
    "        #self.vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "\n",
    "        # Encoder layers\n",
    "\n",
    "        self.encoder_conv_00 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=self.input_channels,\n",
    "                                                          out_channels=64,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(64)\n",
    "                                                ])\n",
    "        self.encoder_conv_01 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=64,\n",
    "                                                          out_channels=64,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(64)\n",
    "                                                ])\n",
    "        self.encoder_conv_10 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=64,\n",
    "                                                          out_channels=128,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(128)\n",
    "                                                ])\n",
    "        self.encoder_conv_11 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=128,\n",
    "                                                          out_channels=128,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(128)\n",
    "                                                ])\n",
    "        self.encoder_conv_20 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=128,\n",
    "                                                          out_channels=256,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(256)\n",
    "                                                ])\n",
    "        self.encoder_conv_21 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=256,\n",
    "                                                          out_channels=256,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(256)\n",
    "                                                ])\n",
    "        self.encoder_conv_22 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=256,\n",
    "                                                          out_channels=256,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(256)\n",
    "                                                ])\n",
    "        self.encoder_conv_30 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=256,\n",
    "                                                          out_channels=512,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                                ])\n",
    "        self.encoder_conv_31 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=512,\n",
    "                                                          out_channels=512,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                                ])\n",
    "        self.encoder_conv_32 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=512,\n",
    "                                                          out_channels=512,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                                ])\n",
    "        self.encoder_conv_40 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=512,\n",
    "                                                          out_channels=512,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                                ])\n",
    "        self.encoder_conv_41 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=512,\n",
    "                                                          out_channels=512,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                                ])\n",
    "        self.encoder_conv_42 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=512,\n",
    "                                                          out_channels=512,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                                ])\n",
    "\n",
    "        #self.init_vgg_weigts()\n",
    "\n",
    "        # Decoder layers\n",
    "\n",
    "        self.decoder_convtr_42 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=512,\n",
    "                                                                   out_channels=512,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                               ])\n",
    "        self.decoder_convtr_41 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=512,\n",
    "                                                                   out_channels=512,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                               ])\n",
    "        self.decoder_convtr_40 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=512,\n",
    "                                                                   out_channels=512,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                               ])\n",
    "        self.decoder_convtr_32 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=512,\n",
    "                                                                   out_channels=512,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                               ])\n",
    "        self.decoder_convtr_31 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=512,\n",
    "                                                                   out_channels=512,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                               ])\n",
    "        self.decoder_convtr_30 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=512,\n",
    "                                                                   out_channels=256,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(256)\n",
    "                                               ])\n",
    "        self.decoder_convtr_22 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=256,\n",
    "                                                                   out_channels=256,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(256)\n",
    "                                               ])\n",
    "        self.decoder_convtr_21 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=256,\n",
    "                                                                   out_channels=256,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(256)\n",
    "                                               ])\n",
    "        self.decoder_convtr_20 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=256,\n",
    "                                                                   out_channels=128,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(128)\n",
    "                                               ])\n",
    "        self.decoder_convtr_11 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=128,\n",
    "                                                                   out_channels=128,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(128)\n",
    "                                               ])\n",
    "        self.decoder_convtr_10 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=128,\n",
    "                                                                   out_channels=64,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(64)\n",
    "                                               ])\n",
    "        self.decoder_convtr_01 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=64,\n",
    "                                                                   out_channels=64,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(64)\n",
    "                                               ])\n",
    "        self.decoder_convtr_00 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=64,\n",
    "                                                                   out_channels=self.output_channels,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1)\n",
    "                                               ])\n",
    "\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        \"\"\"\n",
    "        Forward pass `input_img` through the network\n",
    "        \"\"\"\n",
    "\n",
    "        # Encoder\n",
    "\n",
    "        # Encoder Stage - 1\n",
    "        dim_0 = input_img.size()\n",
    "        x_00 = F.relu(self.encoder_conv_00(input_img))\n",
    "        x_01 = F.relu(self.encoder_conv_01(x_00))\n",
    "        x_0, indices_0 = F.max_pool2d(x_01, kernel_size=2, stride=2, return_indices=True)\n",
    "\n",
    "        # Encoder Stage - 2\n",
    "        dim_1 = x_0.size()\n",
    "        x_10 = F.relu(self.encoder_conv_10(x_0))\n",
    "        x_11 = F.relu(self.encoder_conv_11(x_10))\n",
    "        x_1, indices_1 = F.max_pool2d(x_11, kernel_size=2, stride=2, return_indices=True)\n",
    "\n",
    "        # Encoder Stage - 3\n",
    "        dim_2 = x_1.size()\n",
    "        x_20 = F.relu(self.encoder_conv_20(x_1))\n",
    "        x_21 = F.relu(self.encoder_conv_21(x_20))\n",
    "        x_22 = F.relu(self.encoder_conv_22(x_21))\n",
    "        x_2, indices_2 = F.max_pool2d(x_22, kernel_size=2, stride=2, return_indices=True)\n",
    "\n",
    "        # Encoder Stage - 4\n",
    "        dim_3 = x_2.size()\n",
    "        x_30 = F.relu(self.encoder_conv_30(x_2))\n",
    "        x_31 = F.relu(self.encoder_conv_31(x_30))\n",
    "        x_32 = F.relu(self.encoder_conv_32(x_31))\n",
    "        x_3, indices_3 = F.max_pool2d(x_32, kernel_size=2, stride=2, return_indices=True)\n",
    "\n",
    "        # Encoder Stage - 5\n",
    "        dim_4 = x_3.size()\n",
    "        x_40 = F.relu(self.encoder_conv_40(x_3))\n",
    "        x_41 = F.relu(self.encoder_conv_41(x_40))\n",
    "        x_42 = F.relu(self.encoder_conv_42(x_41))\n",
    "        x_4, indices_4 = F.max_pool2d(x_42, kernel_size=2, stride=2, return_indices=True)\n",
    "\n",
    "        # Decoder\n",
    "\n",
    "        dim_d = x_4.size()\n",
    "\n",
    "        # Decoder Stage - 5\n",
    "        x_4d = F.max_unpool2d(x_4, indices_4, kernel_size=2, stride=2, output_size=dim_4)\n",
    "        x_42d = F.relu(self.decoder_convtr_42(x_4d))\n",
    "        x_41d = F.relu(self.decoder_convtr_41(x_42d))\n",
    "        x_40d = F.relu(self.decoder_convtr_40(x_41d))\n",
    "        dim_4d = x_40d.size()\n",
    "\n",
    "        # Decoder Stage - 4\n",
    "        x_3d = F.max_unpool2d(x_40d, indices_3, kernel_size=2, stride=2, output_size=dim_3)\n",
    "        x_32d = F.relu(self.decoder_convtr_32(x_3d))\n",
    "        x_31d = F.relu(self.decoder_convtr_31(x_32d))\n",
    "        x_30d = F.relu(self.decoder_convtr_30(x_31d))\n",
    "        dim_3d = x_30d.size()\n",
    "\n",
    "        # Decoder Stage - 3\n",
    "        x_2d = F.max_unpool2d(x_30d, indices_2, kernel_size=2, stride=2, output_size=dim_2)\n",
    "        x_22d = F.relu(self.decoder_convtr_22(x_2d))\n",
    "        x_21d = F.relu(self.decoder_convtr_21(x_22d))\n",
    "        x_20d = F.relu(self.decoder_convtr_20(x_21d))\n",
    "        dim_2d = x_20d.size()\n",
    "\n",
    "        # Decoder Stage - 2\n",
    "        x_1d = F.max_unpool2d(x_20d, indices_1, kernel_size=2, stride=2, output_size=dim_1)\n",
    "        x_11d = F.relu(self.decoder_convtr_11(x_1d))\n",
    "        x_10d = F.relu(self.decoder_convtr_10(x_11d))\n",
    "        dim_1d = x_10d.size()\n",
    "\n",
    "        # Decoder Stage - 1\n",
    "        x_0d = F.max_unpool2d(x_10d, indices_0, kernel_size=2, stride=2, output_size=dim_0)\n",
    "        x_01d = F.relu(self.decoder_convtr_01(x_0d))\n",
    "        x_00d = self.decoder_convtr_00(x_01d)\n",
    "        dim_0d = x_00d.size()\n",
    "\n",
    "        x_softmax = F.softmax(x_00d, dim=1)\n",
    "\n",
    "\n",
    "        if DEBUG:\n",
    "            print(\"dim_0: {}\".format(dim_0))\n",
    "            print(\"dim_1: {}\".format(dim_1))\n",
    "            print(\"dim_2: {}\".format(dim_2))\n",
    "            print(\"dim_3: {}\".format(dim_3))\n",
    "            print(\"dim_4: {}\".format(dim_4))\n",
    "\n",
    "            print(\"dim_d: {}\".format(dim_d))\n",
    "            print(\"dim_4d: {}\".format(dim_4d))\n",
    "            print(\"dim_3d: {}\".format(dim_3d))\n",
    "            print(\"dim_2d: {}\".format(dim_2d))\n",
    "            print(\"dim_1d: {}\".format(dim_1d))\n",
    "            print(\"dim_0d: {}\".format(dim_0d))\n",
    "\n",
    "\n",
    "        return x_00d, x_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "CLASSES = {'background', 'person'}\n",
    "\n",
    "PALETTE = {\n",
    "    (0,   0,   0)   : 0 ,   # background\n",
    "    (255, 255, 255) : 1 ,   # person\n",
    "}\n",
    "\n",
    "class UTPDataset(Dataset):\n",
    "    \"\"\"Unite The People 20017 Dataset\"\"\"\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_root_dir = img_dir\n",
    "        \n",
    "        self.img_extension = '_full.png'\n",
    "        self.mask_extension = '_segmentation_full.png'\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if not isinstance(index, int):\n",
    "            index = index.item()\n",
    "        image_id = str(index).zfill(5)\n",
    "        image_path = os.path.join(self.image_root_dir, image_id + self.img_extension)\n",
    "        mask_path = os.path.join(self.image_root_dir, image_id + self.mask_extension)\n",
    "\n",
    "        image = self.load_image(path=image_path)\n",
    "        mask = self.load_mask(path=mask_path)\n",
    "        \n",
    "        data = {\n",
    "                    'image': torch.FloatTensor(image),\n",
    "                    'mask' : torch.FloatTensor(mask)\n",
    "               }\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def load_image(self, path=None):\n",
    "        raw_image = Image.open(path)\n",
    "        raw_image = np.transpose(raw_image.resize((224, 224)), (2,1,0))\n",
    "        imx_t = np.array(raw_image, dtype=np.float32)/255.0\n",
    "\n",
    "        return imx_t\n",
    "\n",
    "    def load_mask(self, path=None):\n",
    "        raw_image = Image.open(path)\n",
    "        raw_image = raw_image.resize((224, 224))\n",
    "        imx_t = np.array(raw_image)\n",
    "        label_seg = np.zeros((2,224,224), dtype=np.int)\n",
    "        \n",
    "        for k in PALETTE:\n",
    "          label_seg[PALETTE[k]][(imx_t==k).all(axis=2)] = 1\n",
    "          \n",
    "        return label_seg\n",
    "      \n",
    "    def __len__(self):\n",
    "        return 10000\n",
    "    \n",
    "#if __name__ == \"__main__\":\n",
    "#    dataset_test = UTPDataset('dataset/dataset')\n",
    "#    data = dataset_test.__getitem__(4)\n",
    "#    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "import sys\n",
    "\n",
    "NUM_INPUT_CHANNELS = 3\n",
    "NUM_OUTPUT_CHANNELS = 2\n",
    "\n",
    "NUM_EPOCHS = 40\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.8\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "def train():\n",
    "  \n",
    "  print(\"Training:\")\n",
    "  prev_loss = float('inf')\n",
    "\n",
    "  for epoch in range(NUM_EPOCHS):\n",
    "    print(\"Epoch #{}\".format(epoch+1))\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "      if phase == 'train':\n",
    "        model.train()\n",
    "      else:\n",
    "        model.eval()\n",
    "      \n",
    "      t_start = time.time()\n",
    "      running_loss = 0.0\n",
    "\n",
    "      for idx, batch in enumerate(data_loaders[phase]):\n",
    "        input_tensor, target_tensor = batch['image'], batch['mask']\n",
    "        \n",
    "        if phase == 'val':\n",
    "            with torch.no_grad():\n",
    "                input_tensor = input_tensor.cuda()\n",
    "                target_tensor = target_tensor.cuda()\n",
    "\n",
    "                predicted_tensor, softmaxed_tensor = model(input_tensor)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(softmaxed_tensor, target_tensor)\n",
    "\n",
    "        else:\n",
    "          input_tensor = input_tensor.cuda()\n",
    "          target_tensor = target_tensor.cuda()\n",
    "\n",
    "          predicted_tensor, softmaxed_tensor = model(input_tensor)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "          loss = criterion(softmaxed_tensor, target_tensor)  \n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "        running_loss += loss.float()\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "          print(\"\\r\\tBatch progress: {:.2f}% [{}/{}]\".format((idx/len(data_loaders[phase]))*100, idx, len(data_loaders[phase])), end='')\n",
    "          sys.stdout.flush()\n",
    "    \n",
    "      delta = time.time() - t_start\n",
    "      print(\"\\t{} Loss: {:.8f}\\tTime: {:.8f}\".format(phase, running_loss, delta))\n",
    "      \n",
    "    if running_loss < prev_loss:\n",
    "        torch.save(model.state_dict(), os.path.join('.', 'epoch-{}.pth'.format(epoch)))\n",
    "        prev_loss = running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:117: UserWarning: \n",
      "    Found GPU2 Quadro 2000 which is of cuda capability 2.1.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Epoch #1\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 117.24591827\tTime: 118.33437490\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 42.25022888\tTime: 28.18516564\n",
      "Epoch #2\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 97.38879395\tTime: 118.96446729\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 41.48890305\tTime: 28.18888259\n",
      "Epoch #3\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 101.12355804\tTime: 119.26787782\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 43.87538528\tTime: 27.56011248\n",
      "Epoch #4\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 101.35745239\tTime: 119.41206837\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 88.01258850\tTime: 28.11262417\n",
      "Epoch #5\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 99.86696625\tTime: 119.29815245\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 42.03345871\tTime: 28.09963512\n",
      "Epoch #6\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 104.28381348\tTime: 119.32145905\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 43.40406036\tTime: 27.53556609\n",
      "Epoch #7\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 104.11907196\tTime: 119.52306700\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 56.35637283\tTime: 27.74894309\n",
      "Epoch #8\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 105.19725037\tTime: 119.35252953\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 41.86252975\tTime: 27.98442245\n",
      "Epoch #9\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 104.54749298\tTime: 119.39061379\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 58.95566559\tTime: 28.14247298\n",
      "Epoch #10\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 122.75891113\tTime: 119.36561990\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 42.62036514\tTime: 27.84005713\n",
      "Epoch #11\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 99.28456879\tTime: 119.66884160\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 41.80519485\tTime: 28.16038990\n",
      "Epoch #12\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 99.50135803\tTime: 119.56948352\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 44.59975433\tTime: 27.75992465\n",
      "Epoch #13\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 98.06166077\tTime: 119.45359874\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 60.46603012\tTime: 27.80430079\n",
      "Epoch #14\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 107.46750641\tTime: 119.77224493\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 40.93535614\tTime: 27.70419240\n",
      "Epoch #15\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 106.83378601\tTime: 119.75177860\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 57.08897400\tTime: 27.68148780\n",
      "Epoch #16\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 116.54633331\tTime: 119.77615404\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 41.42613983\tTime: 27.70562077\n",
      "Epoch #17\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 94.76738739\tTime: 119.70110822\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 41.16796112\tTime: 27.97158217\n",
      "Epoch #18\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 94.72021484\tTime: 119.90615511\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 41.31232834\tTime: 28.23694205\n",
      "Epoch #19\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 94.74813843\tTime: 119.72598433\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 41.06297684\tTime: 27.40235758\n",
      "Epoch #20\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 94.32833862\tTime: 119.82349968\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 41.84186554\tTime: 27.99449420\n",
      "Epoch #21\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 94.39511871\tTime: 119.64943671\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 41.01597977\tTime: 28.12712646\n",
      "Epoch #22\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 127.69561768\tTime: 119.52399826\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 42.05609131\tTime: 27.55209184\n",
      "Epoch #23\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 94.23247528\tTime: 119.92893434\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 40.88662720\tTime: 27.90930343\n",
      "Epoch #24\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 94.15261841\tTime: 119.54658484\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 40.79625702\tTime: 27.66131854\n",
      "Epoch #25\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 93.77197266\tTime: 119.61535311\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 40.88281250\tTime: 28.05369949\n",
      "Epoch #26\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 93.70223236\tTime: 119.61052394\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 40.86602402\tTime: 28.16521859\n",
      "Epoch #27\n",
      "\tBatch progress: 97.14% [340/350]\ttrain Loss: 93.74008942\tTime: 119.66303396\n",
      "\tBatch progress: 93.33% [140/150]\tval Loss: 40.78622055\tTime: 27.76071930\n",
      "Epoch #28\n",
      "\tBatch progress: 40.00% [140/350]"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "full_dataset = UTPDataset(img_dir='dataset/dataset')\n",
    "\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=6)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=6)\n",
    "\n",
    "data_loaders = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  model = SegNet(input_channels=3, output_channels=2).cuda()\n",
    "  criterion = torch.nn.BCELoss().cuda()\n",
    "else:\n",
    "  print('Error: Cuda was not available')\n",
    "  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "train_dataset = UTPDataset(img_dir='dataset/dataset')\n",
    "\n",
    "test_dataloader = DataLoader(train_dataset,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=6)\n",
    "\n",
    "dataiter = iter(test_dataloader)\n",
    "test = dataiter.next()\n",
    "\n",
    "image, mask = test['image'], test['mask']\n",
    "rgb = image[0]\n",
    "rgb.transpose_(0, 2)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.imshow(rgb)\n",
    "\n",
    "image = image.cuda()\n",
    "\n",
    "output = model(image)\n",
    "\n",
    "foo = output[1]\n",
    "foo = foo.cpu()\n",
    "print(foo[0][0].shape)\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.imshow(foo.data.numpy()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
