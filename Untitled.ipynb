{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import pprint\n",
    "\n",
    "F = nn.functional\n",
    "DEBUG = False\n",
    "\n",
    "\n",
    "vgg16_dims = [\n",
    "                    (64, 64, 'M'),                                # Stage - 1\n",
    "                    (128, 128, 'M'),                              # Stage - 2\n",
    "                    (256, 256, 256,'M'),                          # Stage - 3\n",
    "                    (512, 512, 512, 'M'),                         # Stage - 4\n",
    "                    (512, 512, 512, 'M')                          # Stage - 5\n",
    "            ]\n",
    "\n",
    "decoder_dims = [\n",
    "                    ('U', 512, 512, 512),                         # Stage - 5\n",
    "                    ('U', 512, 512, 512),                         # Stage - 4\n",
    "                    ('U', 256, 256, 256),                         # Stage - 3\n",
    "                    ('U', 128, 128),                              # Stage - 2\n",
    "                    ('U', 64, 64)                                 # Stage - 1\n",
    "                ]\n",
    "\n",
    "\n",
    "class SegNet(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(SegNet, self).__init__()\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "\n",
    "        self.num_channels = input_channels\n",
    "\n",
    "        #self.vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "\n",
    "        # Encoder layers\n",
    "\n",
    "        self.encoder_conv_00 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=self.input_channels,\n",
    "                                                          out_channels=64,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(64)\n",
    "                                                ])\n",
    "        self.encoder_conv_01 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=64,\n",
    "                                                          out_channels=64,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(64)\n",
    "                                                ])\n",
    "        self.encoder_conv_10 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=64,\n",
    "                                                          out_channels=128,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(128)\n",
    "                                                ])\n",
    "        self.encoder_conv_11 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=128,\n",
    "                                                          out_channels=128,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(128)\n",
    "                                                ])\n",
    "        self.encoder_conv_20 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=128,\n",
    "                                                          out_channels=256,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(256)\n",
    "                                                ])\n",
    "        self.encoder_conv_21 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=256,\n",
    "                                                          out_channels=256,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(256)\n",
    "                                                ])\n",
    "        self.encoder_conv_22 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=256,\n",
    "                                                          out_channels=256,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(256)\n",
    "                                                ])\n",
    "        self.encoder_conv_30 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=256,\n",
    "                                                          out_channels=512,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                                ])\n",
    "        self.encoder_conv_31 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=512,\n",
    "                                                          out_channels=512,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                                ])\n",
    "        self.encoder_conv_32 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=512,\n",
    "                                                          out_channels=512,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                                ])\n",
    "        self.encoder_conv_40 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=512,\n",
    "                                                          out_channels=512,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                                ])\n",
    "        self.encoder_conv_41 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=512,\n",
    "                                                          out_channels=512,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                                ])\n",
    "        self.encoder_conv_42 = nn.Sequential(*[\n",
    "                                                nn.Conv2d(in_channels=512,\n",
    "                                                          out_channels=512,\n",
    "                                                          kernel_size=3,\n",
    "                                                          padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                                ])\n",
    "\n",
    "        #self.init_vgg_weigts()\n",
    "\n",
    "        # Decoder layers\n",
    "\n",
    "        self.decoder_convtr_42 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=512,\n",
    "                                                                   out_channels=512,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                               ])\n",
    "        self.decoder_convtr_41 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=512,\n",
    "                                                                   out_channels=512,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                               ])\n",
    "        self.decoder_convtr_40 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=512,\n",
    "                                                                   out_channels=512,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                               ])\n",
    "        self.decoder_convtr_32 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=512,\n",
    "                                                                   out_channels=512,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                               ])\n",
    "        self.decoder_convtr_31 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=512,\n",
    "                                                                   out_channels=512,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(512)\n",
    "                                               ])\n",
    "        self.decoder_convtr_30 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=512,\n",
    "                                                                   out_channels=256,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(256)\n",
    "                                               ])\n",
    "        self.decoder_convtr_22 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=256,\n",
    "                                                                   out_channels=256,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(256)\n",
    "                                               ])\n",
    "        self.decoder_convtr_21 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=256,\n",
    "                                                                   out_channels=256,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(256)\n",
    "                                               ])\n",
    "        self.decoder_convtr_20 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=256,\n",
    "                                                                   out_channels=128,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(128)\n",
    "                                               ])\n",
    "        self.decoder_convtr_11 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=128,\n",
    "                                                                   out_channels=128,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(128)\n",
    "                                               ])\n",
    "        self.decoder_convtr_10 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=128,\n",
    "                                                                   out_channels=64,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(64)\n",
    "                                               ])\n",
    "        self.decoder_convtr_01 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=64,\n",
    "                                                                   out_channels=64,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1),\n",
    "                                                nn.BatchNorm2d(64)\n",
    "                                               ])\n",
    "        self.decoder_convtr_00 = nn.Sequential(*[\n",
    "                                                nn.ConvTranspose2d(in_channels=64,\n",
    "                                                                   out_channels=self.output_channels,\n",
    "                                                                   kernel_size=3,\n",
    "                                                                   padding=1)\n",
    "                                               ])\n",
    "\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        \"\"\"\n",
    "        Forward pass `input_img` through the network\n",
    "        \"\"\"\n",
    "\n",
    "        # Encoder\n",
    "\n",
    "        # Encoder Stage - 1\n",
    "        dim_0 = input_img.size()\n",
    "        x_00 = F.relu(self.encoder_conv_00(input_img))\n",
    "        x_01 = F.relu(self.encoder_conv_01(x_00))\n",
    "        x_0, indices_0 = F.max_pool2d(x_01, kernel_size=2, stride=2, return_indices=True)\n",
    "\n",
    "        # Encoder Stage - 2\n",
    "        dim_1 = x_0.size()\n",
    "        x_10 = F.relu(self.encoder_conv_10(x_0))\n",
    "        x_11 = F.relu(self.encoder_conv_11(x_10))\n",
    "        x_1, indices_1 = F.max_pool2d(x_11, kernel_size=2, stride=2, return_indices=True)\n",
    "\n",
    "        # Encoder Stage - 3\n",
    "        dim_2 = x_1.size()\n",
    "        x_20 = F.relu(self.encoder_conv_20(x_1))\n",
    "        x_21 = F.relu(self.encoder_conv_21(x_20))\n",
    "        x_22 = F.relu(self.encoder_conv_22(x_21))\n",
    "        x_2, indices_2 = F.max_pool2d(x_22, kernel_size=2, stride=2, return_indices=True)\n",
    "\n",
    "        # Encoder Stage - 4\n",
    "        dim_3 = x_2.size()\n",
    "        x_30 = F.relu(self.encoder_conv_30(x_2))\n",
    "        x_31 = F.relu(self.encoder_conv_31(x_30))\n",
    "        x_32 = F.relu(self.encoder_conv_32(x_31))\n",
    "        x_3, indices_3 = F.max_pool2d(x_32, kernel_size=2, stride=2, return_indices=True)\n",
    "\n",
    "        # Encoder Stage - 5\n",
    "        dim_4 = x_3.size()\n",
    "        x_40 = F.relu(self.encoder_conv_40(x_3))\n",
    "        x_41 = F.relu(self.encoder_conv_41(x_40))\n",
    "        x_42 = F.relu(self.encoder_conv_42(x_41))\n",
    "        x_4, indices_4 = F.max_pool2d(x_42, kernel_size=2, stride=2, return_indices=True)\n",
    "\n",
    "        # Decoder\n",
    "\n",
    "        dim_d = x_4.size()\n",
    "\n",
    "        # Decoder Stage - 5\n",
    "        x_4d = F.max_unpool2d(x_4, indices_4, kernel_size=2, stride=2, output_size=dim_4)\n",
    "        x_42d = F.relu(self.decoder_convtr_42(x_4d))\n",
    "        x_41d = F.relu(self.decoder_convtr_41(x_42d))\n",
    "        x_40d = F.relu(self.decoder_convtr_40(x_41d))\n",
    "        dim_4d = x_40d.size()\n",
    "\n",
    "        # Decoder Stage - 4\n",
    "        x_3d = F.max_unpool2d(x_40d, indices_3, kernel_size=2, stride=2, output_size=dim_3)\n",
    "        x_32d = F.relu(self.decoder_convtr_32(x_3d))\n",
    "        x_31d = F.relu(self.decoder_convtr_31(x_32d))\n",
    "        x_30d = F.relu(self.decoder_convtr_30(x_31d))\n",
    "        dim_3d = x_30d.size()\n",
    "\n",
    "        # Decoder Stage - 3\n",
    "        x_2d = F.max_unpool2d(x_30d, indices_2, kernel_size=2, stride=2, output_size=dim_2)\n",
    "        x_22d = F.relu(self.decoder_convtr_22(x_2d))\n",
    "        x_21d = F.relu(self.decoder_convtr_21(x_22d))\n",
    "        x_20d = F.relu(self.decoder_convtr_20(x_21d))\n",
    "        dim_2d = x_20d.size()\n",
    "\n",
    "        # Decoder Stage - 2\n",
    "        x_1d = F.max_unpool2d(x_20d, indices_1, kernel_size=2, stride=2, output_size=dim_1)\n",
    "        x_11d = F.relu(self.decoder_convtr_11(x_1d))\n",
    "        x_10d = F.relu(self.decoder_convtr_10(x_11d))\n",
    "        dim_1d = x_10d.size()\n",
    "\n",
    "        # Decoder Stage - 1\n",
    "        x_0d = F.max_unpool2d(x_10d, indices_0, kernel_size=2, stride=2, output_size=dim_0)\n",
    "        x_01d = F.relu(self.decoder_convtr_01(x_0d))\n",
    "        x_00d = self.decoder_convtr_00(x_01d)\n",
    "        dim_0d = x_00d.size()\n",
    "\n",
    "        x_softmax = F.softmax(x_00d, dim=1)\n",
    "\n",
    "\n",
    "        if DEBUG:\n",
    "            print(\"dim_0: {}\".format(dim_0))\n",
    "            print(\"dim_1: {}\".format(dim_1))\n",
    "            print(\"dim_2: {}\".format(dim_2))\n",
    "            print(\"dim_3: {}\".format(dim_3))\n",
    "            print(\"dim_4: {}\".format(dim_4))\n",
    "\n",
    "            print(\"dim_d: {}\".format(dim_d))\n",
    "            print(\"dim_4d: {}\".format(dim_4d))\n",
    "            print(\"dim_3d: {}\".format(dim_3d))\n",
    "            print(\"dim_2d: {}\".format(dim_2d))\n",
    "            print(\"dim_1d: {}\".format(dim_1d))\n",
    "            print(\"dim_0d: {}\".format(dim_0d))\n",
    "\n",
    "\n",
    "        return x_00d, x_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "CLASSES = {'background', 'person'}\n",
    "\n",
    "PALETTE = {\n",
    "    (0,   0,   0)   : 0 ,   # background\n",
    "    (255, 255, 255) : 1 ,   # person\n",
    "}\n",
    "\n",
    "class UTPDataset(Dataset):\n",
    "    \"\"\"Unite The People 20017 Dataset\"\"\"\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_root_dir = img_dir\n",
    "        \n",
    "        self.img_extension = '_full.png'\n",
    "        self.mask_extension = '_segmentation_full.png'\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = str(index.item()).zfill(5)\n",
    "        image_path = os.path.join(self.image_root_dir, image_id + self.img_extension)\n",
    "        mask_path = os.path.join(self.image_root_dir, image_id + self.mask_extension)\n",
    "\n",
    "        image = self.load_image(path=image_path)\n",
    "        mask = self.load_mask(path=mask_path)\n",
    "        \n",
    "        data = {\n",
    "                    'image': torch.FloatTensor(image),\n",
    "                    'mask' : torch.FloatTensor(mask)\n",
    "               }\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def load_image(self, path=None):\n",
    "        raw_image = Image.open(path)\n",
    "        raw_image = np.transpose(raw_image.resize((224, 224)), (2,1,0))\n",
    "        imx_t = np.array(raw_image, dtype=np.float32)/255.0\n",
    "\n",
    "        return imx_t\n",
    "\n",
    "    def load_mask(self, path=None):\n",
    "        raw_image = Image.open(path)\n",
    "        raw_image = raw_image.resize((224, 224))\n",
    "        imx_t = np.array(raw_image)\n",
    "        label_seg = np.zeros((2,224,224), dtype=np.int)\n",
    "        \n",
    "        for k in PALETTE:\n",
    "          label_seg[PALETTE[k]][(imx_t==k).all(axis=2)] = 1\n",
    "          \n",
    "        return label_seg\n",
    "      \n",
    "    def __len__(self):\n",
    "        return 10000\n",
    "    \n",
    "#if __name__ == \"__main__\":\n",
    "#    dataset_test = UTPDataset('dataset/dataset')\n",
    "#    data = dataset_test.__getitem__(4)\n",
    "#    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "import sys\n",
    "\n",
    "NUM_INPUT_CHANNELS = 3\n",
    "NUM_OUTPUT_CHANNELS = 2\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.0001\n",
    "MOMENTUM = 0.8\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "def train():\n",
    "  \n",
    "  print(\"Training:\")\n",
    "    \n",
    "  for epoch in range(NUM_EPOCHS):\n",
    "    print(\"Epoch #{}\".format(epoch+1))\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "      if phase == 'train':\n",
    "        model.train()\n",
    "      else:\n",
    "        model.eval()\n",
    "      \n",
    "      t_start = time.time()\n",
    "      running_loss = 0.0\n",
    "\n",
    "      for idx, batch in enumerate(data_loaders[phase]):\n",
    "        input_tensor, target_tensor = batch['image'], batch['mask']\n",
    "        \n",
    "        if phase == 'val':\n",
    "            with torch.no_grad():\n",
    "                input_tensor = input_tensor.cuda()\n",
    "                target_tensor = target_tensor.cuda()\n",
    "\n",
    "                predicted_tensor, softmaxed_tensor = model(input_tensor)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(softmaxed_tensor, target_tensor)\n",
    "\n",
    "        else:\n",
    "          input_tensor = input_tensor.cuda()\n",
    "          target_tensor = target_tensor.cuda()\n",
    "\n",
    "          predicted_tensor, softmaxed_tensor = model(input_tensor)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "          loss = criterion(softmaxed_tensor, target_tensor)  \n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "        running_loss += loss.float()\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "          print(\"\\r\\tBatch progress: {:.2f}% [{}/{}]\".format((idx/len(data_loaders[phase]))*100, idx, len(data_loaders[phase])), end='')\n",
    "          sys.stdout.flush()\n",
    "    \n",
    "      delta = time.time() - t_start\n",
    "      print(\"\\t{} Loss: {:.8f}\\tTime: {:.8f}\".format(phase, running_loss, delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/torch/cuda/__init__.py:117: UserWarning: \n",
      "    Found GPU2 Quadro 2000 which is of cuda capability 2.1.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Epoch #1\n",
      "\tBatch progress: 99.43% [870/875]\ttrain Loss: 351.24844360\tTime: 125.78005433\n",
      "\tBatch progress: 98.67% [370/375]\tval Loss: 111.38411713\tTime: 42.46798229\n",
      "Epoch #2\n",
      "\tBatch progress: 18.29% [160/875]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 1396) is killed by signal: Bus error. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c6d96ff5b3b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-397073a600e8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m           \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m           \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 1396) is killed by signal: Bus error. "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "full_dataset = UTPDataset(img_dir='dataset/dataset')\n",
    "\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=4)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=4)\n",
    "\n",
    "data_loaders = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  model = SegNet(input_channels=3, output_channels=2).cuda()\n",
    "  criterion = torch.nn.BCELoss().cuda()\n",
    "else:\n",
    "  print('Error: Cuda was not available')\n",
    "  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
